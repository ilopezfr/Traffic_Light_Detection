{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_light_classifier_bosch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vjSBDcAxZ20r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Traffic Light Classifier using Bosch dataset\n",
        "I’ll be creating a traffic light classifier which will try to determine if the light is green, yellow, or red. Currently the pre-trained models only try to detect if there is a traffic light in the image, not the state of the traffic light.\n",
        "\n",
        "Steps:\n",
        "1. selecting a model\n",
        "2. adapting an existing data set\n",
        "3. creating and annotating your own data set\n",
        "4. modifying the model config file\n",
        "5. training the model\n",
        "6. saving the model\n",
        "7. finally deploying the model in another piece of software.\n",
        "\n",
        "#### Installation\n",
        "\n",
        "Download the repos"
      ]
    },
    {
      "metadata": {
        "id": "QE3pqtw8Z1u8",
        "colab_type": "code",
        "outputId": "b0bf4644-f72c-439b-accb-12633ff20703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 24307, done.\u001b[K\n",
            "remote: Total 24307 (delta 0), reused 0 (delta 0), pack-reused 24307\u001b[K\n",
            "Receiving objects: 100% (24307/24307), 507.59 MiB | 30.36 MiB/s, done.\n",
            "Resolving deltas: 100% (14131/14131), done.\n",
            "Checking out files: 100% (2808/2808), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3P5IfHFV8fGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "920eb952-cf02-4cab-a3ae-030b8ad89f67"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ThomasHenckel/CarND-Capstone"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CarND-Capstone'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 726 (delta 8), reused 18 (delta 8), pack-reused 699\u001b[K\n",
            "Receiving objects: 100% (726/726), 41.25 MiB | 28.97 MiB/s, done.\n",
            "Resolving deltas: 100% (417/417), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCWZ5tEp8mHc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download Bosch dataset"
      ]
    },
    {
      "metadata": {
        "id": "kqDnDEHorAcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "--5ybFee8lRl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir dataset && cd dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAjYA5o89RJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.kaggle.com/mbornoe/lisa-traffic-light-dataset/downloads/lisa-traffic-light-dataset.zip/2\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QphaXbp0-_WG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download LISA dataset (from Kaggle)"
      ]
    },
    {
      "metadata": {
        "id": "xU80nSFS_CiX",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cd84c7f3-086b-49db-8a76-108ab51b8947"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-75117c86-7036-42eb-9e58-69783626effa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-75117c86-7036-42eb-9e58-69783626effa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ilopezfr\",\"key\":\"54a1d43df05cc80ab9d46edb4b102252\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "7TZQpL_U_MFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a95c3af-b937-400c-d9b8-d24fb7cddb6a"
      },
      "cell_type": "code",
      "source": [
        "# Setup kaggle Dir; copy json file; chmod\n",
        "import os\n",
        "os.chdir('/content/dataset') \n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rqoJsIXO_MQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "113c1901-8a38-42be-9760-fb3429a1edff"
      },
      "cell_type": "code",
      "source": [
        "# verify json content\n",
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw------- 1 root root 64 Mar  3 00:39 kaggle.json\n",
            "{\"username\":\"ilopezfr\",\"key\":\"54a1d43df05cc80ab9d46edb4b102252\"}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eRzbryS7_f0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "bcf18dfb-5ba7-49c9-e48d-811e62813b4a"
      },
      "cell_type": "code",
      "source": [
        "#Install kaggle packages\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli\n",
        "\n",
        "#List Kaggle DataSets\n",
        "!kaggle datasets list"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 1.1MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 92kB 24.0MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.8MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Building wheel for cliff (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25href                                                          title                                                size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "ronitf/heart-disease-uci                                     Heart Disease UCI                                     3KB  2018-06-25 11:33:56          11533  \n",
            "russellyates88/suicide-rates-overview-1985-to-2016           Suicide Rates Overview 1985 to 2016                 396KB  2018-12-01 19:18:25           8074  \n",
            "karangadiya/fifa19                                           FIFA 19 complete player dataset                       2MB  2018-12-21 03:52:59          11092  \n",
            "lava18/google-play-store-apps                                Google Play Store Apps                                2MB  2019-02-03 13:55:47          39257  \n",
            "bigquery/crypto-ethereum-classic                             Ethereum Classic Blockchain                          66GB  2019-02-05 17:41:48              0  \n",
            "mohansacharya/graduate-admissions                            Graduate Admissions                                   9KB  2018-12-28 10:07:14          11400  \n",
            "iarunava/cell-images-for-detecting-malaria                   Malaria Cell Images Dataset                         337MB  2018-12-05 05:40:21           2079  \n",
            "jessicali9530/stanford-dogs-dataset                          Stanford Dogs Dataset                               735MB  2019-02-13 05:45:25            787  \n",
            "noriuk/us-education-datasets-unification-project             U.S. Education Datasets: Unification Project         85MB  2019-03-02 18:41:52           1603  \n",
            "safegraph/visit-patterns-by-census-block-group               Consumer & Visitor Insights For Neighborhoods        66MB  2018-12-19 21:31:50            606  \n",
            "cityofLA/los-angeles-parking-citations                       Los Angeles Parking Citations                       245MB  2019-02-26 22:18:28           1994  \n",
            "jutrera/stanford-car-dataset-by-classes-folder               Stanford Car Dataset by classes folder                2GB  2018-07-02 07:35:45           1899  \n",
            "vjchoudhary7/customer-segmentation-tutorial-in-python        Mall Customer Segmentation Data                       2KB  2018-08-11 07:23:02           3323  \n",
            "safegraph/census-block-group-american-community-survey-data  Census Block Group American Community Survey Data     2GB  2018-12-22 00:29:56            386  \n",
            "rmisra/news-headlines-dataset-for-sarcasm-detection          News Headlines Dataset For Sarcasm Detection          2MB  2018-06-09 22:14:56           1449  \n",
            "fivethirtyeight/fivethirtyeight-comic-characters-dataset     FiveThirtyEight Comic Characters Dataset            577KB  2019-02-01 15:02:23           1313  \n",
            "anokas/kuzushiji                                             Kuzushiji-MNIST                                     318MB  2018-12-17 01:19:31            451  \n",
            "jessicali9530/celeba-dataset                                 CelebFaces Attributes (CelebA) Dataset                1GB  2018-06-01 20:08:48           4518  \n",
            "pavansanagapati/urban-sound-classification                   Urban Sound Classification                            6GB  2018-06-16 13:44:36           1548  \n",
            "mdhrumil/top-5000-youtube-channels-data-from-socialblade     Top 5000 Youtube channels data from Socialblade.    128KB  2018-09-09 14:05:54           3829  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdXlVPgO_gfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfb66cd9-d5b6-486d-f80a-0ec4bb62e338"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/dataset')\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lisa-traffic-light-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U_AeET3T_g7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d88009ce-0e78-43d5-c750-c96d1cb6f8d0"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/dataset')\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  lisa-traffic-light-dataset.zip\n",
            "  inflating: daySequence1.zip        \n",
            "  inflating: nightSequence1.zip      \n",
            "  inflating: dayTrain.zip            \n",
            "  inflating: daySequence2.zip        \n",
            "  inflating: sample-dayClip6.zip     \n",
            "  inflating: sample-nightClip1.zip   \n",
            "  inflating: nightTrain.zip          \n",
            "  inflating: Annotations.zip         \n",
            "  inflating: nightSequence2.zip      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cjr5vDeyIvj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/dataset')\n",
        "!unzip daySequence1.zip && unzip Annotations.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkksIpuXJy0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download Udacity Camera Feed"
      ]
    },
    {
      "metadata": {
        "id": "kwT66WcYJx9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ab71f82c-9d67-42ee-d35a-cb88af6fae52"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sIJ6R5BV8wTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "07901d17-c6fe-4f2f-f884-9e3f3412162d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip \"/content/gdrive/My Drive/Colab Notebooks/data/traffic_light_bag_files.zip\" -d /content/dataset"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/Colab Notebooks/data/traffic_light_bag_files.zip\n",
            "replace /content/dataset/just_traffic_light.bag? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /content/dataset/just_traffic_light.bag  y\n",
            "\n",
            "  inflating: /content/dataset/loop_with_traffic_light.bag  A\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vk-0YIgqPZC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Move traffic_light_dataset to the datasets location:\n",
        "import shutil\n",
        "shutil.move(\"/content/gdrive/My Drive/Colab Notebooks/data/traffic_light_dataset\", \"/content/dataset\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNZB5WZofRz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "16afe768-68a8-4b65-bd46-dfa52182e4a9"
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/dataset/traffic_light_dataset/carla/carla.zip"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/dataset/traffic_light_dataset/carla/carla.zip\n",
            "replace carla/testing/labels/uda_2_g_0001.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9J7QAx4aKQA",
        "colab_type": "code",
        "outputId": "9070a9c3-095f-45d1-a12c-e38b2dfb7666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/models/research')\n",
        "\n",
        "os.environ['PYTHONPATH'] += \":/content/models\"\n",
        "os.getcwd()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "93dRNluZdtpD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip3 install --user -r models/official/requirements.txt\n",
        "!pip3 install --user Cython\n",
        "!pip3 install --user contextlib2\n",
        "!pip3 install --user jupyter\n",
        "!pip3 install --user matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLVqvmzV2D1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2f2ab2b3-97ff-4d04-e7bc-6960da550f3f"
      },
      "cell_type": "code",
      "source": [
        "# COCO API Installation ---> not working\n",
        "# From tensorflow/models/research/\n",
        "os.chdir('/content/models/research')\n",
        "!rm -r cocoapi\n",
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 947, done.\u001b[K\n",
            "Receiving objects:   0% (1/947)   \rReceiving objects:   1% (10/947)   \rReceiving objects:   2% (19/947)   \rReceiving objects:   3% (29/947)   \rReceiving objects:   4% (38/947)   \rReceiving objects:   5% (48/947)   \rReceiving objects:   6% (57/947)   \rReceiving objects:   7% (67/947)   \rReceiving objects:   8% (76/947)   \rReceiving objects:   9% (86/947)   \rReceiving objects:  10% (95/947)   \rReceiving objects:  11% (105/947)   \rReceiving objects:  12% (114/947)   \rReceiving objects:  13% (124/947)   \rReceiving objects:  14% (133/947)   \rReceiving objects:  15% (143/947)   \rReceiving objects:  16% (152/947)   \rReceiving objects:  17% (161/947)   \rReceiving objects:  18% (171/947)   \rReceiving objects:  19% (180/947)   \rReceiving objects:  20% (190/947)   \rReceiving objects:  21% (199/947)   \rReceiving objects:  22% (209/947)   \rReceiving objects:  23% (218/947)   \rReceiving objects:  24% (228/947)   \rReceiving objects:  25% (237/947)   \rReceiving objects:  26% (247/947)   \rReceiving objects:  27% (256/947)   \rReceiving objects:  28% (266/947)   \rReceiving objects:  29% (275/947)   \rReceiving objects:  30% (285/947)   \rReceiving objects:  31% (294/947)   \rReceiving objects:  32% (304/947)   \rReceiving objects:  33% (313/947)   \rReceiving objects:  34% (322/947)   \rReceiving objects:  35% (332/947)   \rReceiving objects:  36% (341/947)   \rReceiving objects:  37% (351/947)   \rReceiving objects:  38% (360/947)   \rReceiving objects:  39% (370/947)   \rReceiving objects:  40% (379/947)   \rReceiving objects:  41% (389/947)   \rReceiving objects:  42% (398/947)   \rReceiving objects:  43% (408/947)   \rReceiving objects:  44% (417/947)   \rReceiving objects:  45% (427/947)   \rReceiving objects:  46% (436/947)   \rReceiving objects:  47% (446/947)   \rReceiving objects:  48% (455/947)   \rReceiving objects:  49% (465/947)   \rReceiving objects:  50% (474/947)   \rReceiving objects:  51% (483/947)   \rReceiving objects:  52% (493/947)   \rReceiving objects:  53% (502/947)   \rReceiving objects:  54% (512/947)   \rReceiving objects:  55% (521/947)   \rReceiving objects:  56% (531/947)   \rReceiving objects:  57% (540/947)   \rReceiving objects:  58% (550/947)   \rReceiving objects:  59% (559/947)   \rReceiving objects:  60% (569/947)   \rReceiving objects:  61% (578/947)   \rReceiving objects:  62% (588/947)   \rReceiving objects:  63% (597/947)   \rReceiving objects:  64% (607/947)   \rReceiving objects:  65% (616/947)   \rReceiving objects:  66% (626/947)   \rReceiving objects:  67% (635/947)   \rReceiving objects:  68% (644/947)   \rReceiving objects:  69% (654/947)   \rReceiving objects:  70% (663/947)   \rReceiving objects:  71% (673/947)   \rReceiving objects:  72% (682/947)   \rReceiving objects:  73% (692/947)   \rReceiving objects:  74% (701/947)   \rReceiving objects:  75% (711/947)   \rReceiving objects:  76% (720/947)   \rReceiving objects:  77% (730/947)   \rReceiving objects:  78% (739/947)   \rReceiving objects:  79% (749/947)   \rReceiving objects:  80% (758/947)   \rReceiving objects:  81% (768/947)   \rReceiving objects:  82% (777/947)   \rReceiving objects:  83% (787/947)   \rReceiving objects:  84% (796/947)   \rReceiving objects:  85% (805/947)   \rReceiving objects:  86% (815/947)   \rremote: Total 947 (delta 0), reused 0 (delta 0), pack-reused 947\u001b[K\n",
            "Receiving objects: 100% (947/947), 11.69 MiB | 36.15 MiB/s, done.\n",
            "Resolving deltas: 100% (565/565), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qIfFNIKDur-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "88589aaa-fcec-4e3b-939d-bcb991a2345c"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/models/research/cocoapi/PythonAPI')\n",
        "!bash -c 'make' \n",
        "#!sudo make install\n",
        "#!bash -c 'cp -r content/models/research/cocoapi/PythonAPI/pycocotools content/models/research'"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 1, in <module>\n",
            "    from setuptools import setup, Extension\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/setuptools/__init__.py\", line 20, in <module>\n",
            "    from setuptools.dist import Distribution, Feature\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/setuptools/dist.py\", line 36, in <module>\n",
            "    from setuptools import windows_support\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/setuptools/windows_support.py\", line 2, in <module>\n",
            "    import ctypes\n",
            "  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 149, in __enter__\n",
            "  File \"<frozen importlib._bootstrap>\", line 88, in acquire\n",
            "KeyboardInterrupt\n",
            "Makefile:3: recipe for target 'all' failed\n",
            "make: *** [all] Error 1\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BfdaB82eoSsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Protobuf compilation\n",
        "# From tensorflow/models/research/\n",
        "os.chdir('/content/models/research')\n",
        "#!protoc object_detection/protos/*.proto --python_out=.\n",
        "!wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
        "!unzip protobuf.zip\n",
        "!./bin/protoc object_detection/protos/*.proto --python_out=.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oNMcsvUocns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From tensorflow/models/research/\n",
        "#export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
        "os.chdir('/content/models/research')\n",
        "os.environ['PYTHONPATH'] += \":/content/models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bk8i6dgIolkp",
        "colab_type": "code",
        "outputId": "2917dc1e-7f8e-4da7-b81a-bd9da4ca4b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the installation\n",
        "os.chdir('/content/models/research')\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_test.py\", line 23, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "ModuleNotFoundError: No module named 'object_detection'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oMtZkDoV3xqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "801Zn2RU30VG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training a Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Lq867uDm36-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c90dd92a-a5e4-467c-cd16-7efdc92e97f8"
      },
      "cell_type": "code",
      "source": [
        "# move object detection models from TF to our CarND-Capstone folder\n",
        "os.chdir('/content/CarND-Capstone/Traffic_Light_Detection')\n",
        "!mkdir models\n",
        "\n",
        "#!cp -r /content/models/research/object_detection content/CarND-Capstone/Traffic_Light_Detection\n",
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-03 05:44:46--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.20.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.20.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128048406 (122M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_coco_11_06_2017.tar.gz.2’\n",
            "\n",
            "ssd_mobilenet_v1_co 100%[===================>] 122.12M   214MB/s    in 0.6s    \n",
            "\n",
            "2019-03-03 05:44:46 (214 MB/s) - ‘ssd_mobilenet_v1_coco_11_06_2017.tar.gz.2’ saved [128048406/128048406]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EDBi6-peDpr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "37ce8fac-1752-45d8-f1c2-f35ffb54b48d"
      },
      "cell_type": "code",
      "source": [
        "!tar -xvzf  /content/CarND-Capstone/Traffic_Light_Detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz -C /content/CarND-Capstone/Traffic_Light_Detection/models"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v1_coco_11_06_2017/\n",
            "ssd_mobilenet_v1_coco_11_06_2017/model.ckpt.index\n",
            "ssd_mobilenet_v1_coco_11_06_2017/model.ckpt.meta\n",
            "ssd_mobilenet_v1_coco_11_06_2017/frozen_inference_graph.pb\n",
            "ssd_mobilenet_v1_coco_11_06_2017/model.ckpt.data-00000-of-00001\n",
            "ssd_mobilenet_v1_coco_11_06_2017/graph.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VCLvOtJG37Iv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run the training session\n",
        "python object_detection/model_main.py --pipeline_config_path=content/CarND-Capstone/Traffic_Light_Detection/training/ssd_mobilenet_v1_coco.config --model_dir=models/fine_tuned/ssd_inception\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "623fJDo8bjsv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing a Model: Object Detection Demo\n",
        "\n",
        "In the models/research/objection_detection/ folder, open up the jupyter notebook object_detection_tutorial.ipynb and run the entire notebook. \n",
        "(https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb)\n",
        "\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "ezGrRwgOa4qx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure you are in /content/models/research. If not, use:\n",
        "# os.chdir('/content/models/research')\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import static_shape\n",
        "from object_detection.utils import shape_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-LELdNEbztI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Env Setup - This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "os.chdir('/content/models/research')\n",
        "\n",
        "# Object detection imports\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-jIqpHHqPZT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Preparation\n",
        "\n",
        "## Variables\n",
        "\n",
        "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  \n",
        "\n",
        "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies.\n"
      ]
    },
    {
      "metadata": {
        "id": "rdZ-Wn1xg9O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What model to download.\n",
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9niWOODtCb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the model"
      ]
    },
    {
      "metadata": {
        "id": "DORkHfm1qubm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6l2kCf5tR11",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load a (frozen) Tensorflow model into memory."
      ]
    },
    {
      "metadata": {
        "id": "Sr46ieBctSyE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYZJ3VDOtTD3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading label map\n",
        "Label_maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
      ]
    },
    {
      "metadata": {
        "id": "VndkZ1E21MIn",
        "colab_type": "code",
        "outputId": "fb3a96a7-5dc7-4a6a-c919-2e8f61f16749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        }
      },
      "cell_type": "code",
      "source": [
        "label_map = label_map_util.load_labelmap(os.path.join('/home/user/anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data', 'mscoco_label_map.pbtxt'))\n",
        "\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-69d127085621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/user/anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mscoco_label_map.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_label_map_to_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/research/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36mload_labelmap\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \"\"\"\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mlabel_map_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIntLabelMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 85\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /home/user/anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data/mscoco_label_map.pbtxt; No such file or directory"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0Xpruv69tDNA",
        "colab_type": "code",
        "outputId": "d7bcbca1-05af-488e-f9a3-07ca4fb7b756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "#category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "label_map = label_map_util.load_labelmap(os.path.join('anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data', 'mscoco_label_map.pbtxt'))\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=4, use_display_name=True) # Loads label map proto and returns categories list compatible with eval.\n",
        "category_index = label_map_util.create_category_index(categories) # Creates dictionary of COCO compatible categories keyed by category id.\n",
        "print(category_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4d5e2d746825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mscoco_label_map.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_label_map_to_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loads label map proto and returns categories list compatible with eval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Creates dictionary of COCO compatible categories keyed by category id.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/research/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36mload_labelmap\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \"\"\"\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mlabel_map_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIntLabelMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 85\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: anaconda3/lib/python3.6/site-packages/tensorflow/models/research/object_detection/data/mscoco_label_map.pbtxt; No such file or directory"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3oaLKGIttjHx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}